# 验证两台机器是否能通过多播发现对方（DDS 发现的基础）
ros2 multicast receive  # 在服务器端运行
ros2 multicast send     # 在树莓派端运行，看服务器是否有输出

# 检查节点之间的逻辑连接（查看整个计算图）
ros2 node list
ros2 node info /your_slam_node_name

# 查看所有话题，确认远端话题是否已经出现在列表中
ros2 topic list -t      # -t 会显示话题类型，方便排查

# 查看 CycloneDDS 的当前配置（确认 XML 是否生效）
ros2 doctor --report | grep rmw

# 实时监测网络流量与丢包（需要安装 cyclonedds-tools）
# sudo apt install ros-jazzy-cyclonedds-tools
ros2 run cyclonedds_cpp_tools cyclone_find_topic /camera/image_raw

# 强制刷新发现机制（有时节点重启后没对上，可以用这个查看）
ros2 run cyclonedds_cpp_tools cyclone_list_nodes

# 查看话题的详细 QoS 设置
# 重点检查：Reliability (可靠性) 和 Durability (持久性)
ros2 topic info /camera/image_raw --verbose

# 手动指定 QoS 打印话题（如果对方是 SensorDataQoS，普通 echo 可能没数据）
# 单目视觉和 IMU 通常使用 'sensor_data' 策略
ros2 topic echo /camera/image_raw --qos-profile sensor_data

# 检查消息频率是否稳定（判断 WiFi 是否堵塞）
ros2 topic hz /camera/image_raw    # 图像频率
ros2 topic hz /imu/data            # IMU 频率
ros2 topic bw /camera/image_raw    # 查看实际占用的带宽（Mbps）

# 检查图像消息从树莓派发出到服务器接收的时间延迟
# (前提：两台机器已通过 chrony 进行时间同步)
ros2 topic delay /camera/image_raw

# 查看 TF 树是否完整，以及是否存在过期数据
ros2 run tf2_tools view_frames
# 在 Jazzy 中，建议使用：
ros2 run tf2_ros tf2_monitor

# 仿真环境安装
sudo apt update && sudo apt install curl gnupg lsb-release -y
sudo curl https://packages.osrfoundation.org/gazebo.gpg --output /usr/share/keyrings/pkgs-osr-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/pkgs-osr-archive-keyring.gpg] http://packages.osrfoundation.org/gazebo/ubuntu-stable $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/gazebo-stable.list > /dev/null

sudo apt update
sudo apt install gz-harmonic

export GZ_PARTITION=sim
gz sim -v 4 shapes.sdf

# 架构
# ORB-/SLAM3 节点（视觉里程计 +地图特征）
slam3 (ORB-SLAM3) --
    subscribes: /camera/image_raw, /camera/camera_info, /imu/data_raw (if visual-inertial)
    publishes:
        /slam3/pose             (geometry_msgs/PoseStamped)   frame_id: map
        /slam3/odom             (nav_msgs/Odometry)           odom->base_link  线速度偏移较大 TODO
        /slam3/map_points       (sensor_msgs/PointCloud2)     （供可视化或稠密化）
        /slam3/debug_image      (sensor_msgs/Image)           debug visualization (Foxglove)
    broadcasts:
        TF: map -> map -> odom

# robot_localization (EKF) — 融合 IMU + slam3/odom
ekf_localization_node --
    subscribes: /imu/data_raw, /slam3/odom
    publishes:
        /odometry/filtered     (nav_msgs/Odometry)         frame_id: odom (-> base_footprint)
    broadcasts:
        TF: odom -> base_link

# Nav2 (导航堆栈)
nav2 (bt_navigator, planner_server, controller_server, costmap) --
    subscribes:
        /map  (OccupancyGrid): 来自 rtabmap 或 slam_toolbox 的全局地图
        odom topic (set 为 /odometry/filtered 或 /odom)
        /scan (LaserScan): 用于 obstacle_layer 避障。
        /points (PointCloud2): 深度相机数据，用于检测高处或低处障碍物。
        /initialpose: 用于手动初始化机器人在地图中的位姿。
    publishes:
        cmd_vel -> robot base controller (geometry_msgs/Twist)
        /plan: 规划的全局路径。
        /local_plan: 局部控制器生成的轨迹。
    uses tf: map -> odom, odom -> base_link, base_link -> sensors 必须包含完整的坐标变换树。

# collision_monitor (Nav2 或自定义)
collision_monitor --
    subscribes: rtabmap pointclouds 或 local_costmap topics
    triggers safety stops / emergency behaviors -> cmd_vel (or into Nav2 lifecycle)


# RTAB-Map 用于生成导航地图（占领网格 / 点云）
# 废弃，无法使用单目相机生成地图
rtabmap --
    subscribes: /camera/image_raw, /camera/camera_info, optionally /slam3/pose or /odom
    publishes:
        /map                    (nav_msgs/OccupancyGrid) or /rtabmap/grid_map
        /rtabmap/points         (sensor_msgs/PointCloud2) (map points / obstacles)
    note: 如果你用 SLAM3 做定位，RTAB-Map 可仅负责稠密重建 / 占用网格生成。
## 目标tf
map (全局坐标系)
 └── odom (局部连续坐标系)  <-- [由 EKF 发布]
      └── base_footprint (机器人投影) <-- [由 EKF 发布]
           └── base_link (机器人本体) <-- [由 Static TF 发布]
                ├── imu_link (惯性单元)
                └── camera_link (相机外壳)
                     └── camera_link_optical (算法核心坐标系)

## 地图生成方案：
1. RTAB-Map：但支持单目输入。通过 Mem/StereoFromMotion 参数，它可以利用相机运动产生的位移（SFM）来估计深度并构建占据网格图（Occupancy Grid Map）。
2.  它能发布 map -> odom 的 TF 变换。你可以使用 orb_slam3_ros_wrapper 将其稀疏特征点云转化为 Nav2 可识别的消息。
## 
1. 使用 YOLOv8-Seg,将分割出的非地面区域（障碍物）通过几何投影映射到地平面的极坐标系，伪造出 /scan (LaserScan) 用于局部代价地图  TODO
2.单目深度估计 (Monocular Depth Estimation):Depth-Anything 或 MiDaS 模型，将单目 RGB 图实时转化为“伪深度图”。配合 depthimage_to_laserscan 插件，将伪深度图转化为标准的 /scan 信号 REJECT （模型太大，算力要求极高）
3.直接在图像上运行目标检测（YOLO），当检测到“人”或“障碍物”且其在图像底部的像素坐标超过安全阈值时，直接给 collision_monitor 发送一个虚拟的距离信号或触发底盘停止。