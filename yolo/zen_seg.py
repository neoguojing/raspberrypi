import argparse
import zenoh
import numpy as np
import cv2
import json
import math
import time
import sys
import struct
import os
import glob
import threading
# from robot.robot.vision.detector import SegDetector # å‡è®¾ä½ çš„ SegDetector å·²ç»æ”¹é€ ä¸º ONNX
from robot.robot.vision.segformer import SegFormerDetector 

class ZenohSegScan:
    def __init__(self, config_path='config.json'):
        
        self.frame_count = 0
        self.skip_n = 3 # æ¯ 3 å¸§å¤„ç† 1 å¸§
        
        # --- 1. å‚æ•°è®¾ç½® (æ¨¡æ‹Ÿ ROS 2 Parameter) ---
        self.camera_x_offset = 0.1
        self.camera_y_offset = 0.0
        self.camera_height = 0.071
        self.camera_pitch = 0.1484
        
        # æ¿€å…‰é›·è¾¾æ¨¡æ‹Ÿå‚æ•°
        self.angle_min = -1.0
        self.angle_max = 1.0
        self.angle_increment = 0.017
        self.num_readings = int(round((self.angle_max - self.angle_min) / self.angle_increment)) + 1
        self.range_min = 0.1
        self.range_max = 3.0
        # ç‰©ç†æ¨¡æ‹Ÿï¼šå‡è®¾æ¿€å…‰å…‰æ–‘æœ‰ 1.5 å€è§’åˆ†è¾¨ç‡çš„å®½åº¦ï¼Œäº§ç”Ÿé‡å 
        self.beam_overlap_indices = 2

        # åŠ è½½ç›¸æœºå†…å‚
        self.load_sensor_config(config_path)

        # åˆå§‹åŒ–æ£€æµ‹å™¨
        # self.detector = SegDetector(conf=0.05)
        self.detector = SegFormerDetector()
        
        # --- 2. Zenoh åˆå§‹åŒ– ---
        print("ğŸ”— æ­£åœ¨è¿æ¥åˆ° Zenoh ç½‘ç»œ...")
        config = zenoh.Config()
        config.insert_json5(
            "connect/endpoints",
            '["tcp/127.0.0.1:7447"]'
        )
        self.session = zenoh.open(config)
        
        # è¯é¢˜å®šä¹‰ (å¯¹åº” ROS 2 Bridge æ˜ å°„è·¯å¾„)
        # å‡è®¾ ROS 2 è¯é¢˜æ˜¯ /camera/image_raw/compressed
        self.image_topic = "rt/camera/image_raw"
        self.image_topic_compress = "rt/camera/image_raw/compressed"
        self.scan_topic = "rt/scan"
        self.point_cloud_topic = "rt/pointcloud"

        # è®¢é˜…å›¾åƒ
        self.sub = self.session.declare_subscriber(self.image_topic, self.on_image_data)
        self.sub_compress = self.session.declare_subscriber(self.image_topic_compress, self.on_image_data)

        # å®šä¹‰å‘å¸ƒè€… (å‘é€å¤„ç†åçš„ JSON)
        self.pub = self.session.declare_publisher(self.scan_topic)
        self.pointcloud_pub = self.session.declare_publisher(self.point_cloud_topic)
        
        self.latest_sample = None
        self.sample_lock = threading.Lock()
        self.last_valid_scan = np.full(self.num_readings, self.range_max)
        self.scan_alpha = 0.2
        
        # å¯åŠ¨ä¸€ä¸ªç‹¬ç«‹çš„å¤„ç†çº¿ç¨‹
        self.process_thread = threading.Thread(target=self.processing_loop, daemon=True)
        self.process_thread.start()

        print(f"âœ… èŠ‚ç‚¹å·²å°±ç»ª. è®¢é˜…: {self.image_topic},{self.image_topic_compress}, å‘å¸ƒ: {self.scan_topic}")

    def load_sensor_config(self, path):
        with open(path, 'r') as f:
            config = json.load(f)
        print(f"camera config:{config}")
        self.K = np.array(config['camera_matrix'], dtype=np.float32)
        self.dist_coeffs = np.array(config['dist_coeffs'], dtype=np.float32)
        self.cy = self.K[1, 2]
        self.width = config['width']
        self.height = config['height']

    def on_image_data(self, sample):
        """å›è°ƒå‡½æ•°ç°åœ¨æå¿«ï¼šåªè´Ÿè´£å­˜ä¸‹æœ€æ–°çš„æ•°æ®åŒ…"""
        with self.sample_lock:
            self.latest_sample = sample  # è¦†ç›–æ—§çš„æ ·æœ¬ï¼Œç›´æ¥ä¸¢å¼ƒç§¯å‹å¸§
            
    def processing_loop(self):
        """Zenoh è®¢é˜…å›è°ƒ"""
        while True:
            try:
                sample = None
                with self.sample_lock:
                    if self.latest_sample is not None:
                        sample = self.latest_sample
                        self.latest_sample = None # å¤„ç†å®Œåæ¸…ç©º
                if sample is None:
                    time.sleep(0.005) # æ²¡æ•°æ®æ—¶å¾®ä¼‘çœ 
                    continue
                
                self.frame_count += 1
                # 1. è§£ç å›¾åƒ (å‡è®¾æ˜¯ CompressedImage å­—èŠ‚æµ) æˆ–è€… Imageå­—èŠ‚æµ
                # ROS 2 Bridge ä¼ è¾“çš„ CompressedImage è´Ÿè½½é€šå¸¸å°±æ˜¯ JPEG æ•°æ®
                # ä½†æ³¨æ„ï¼šæŸäº› Bridge å¯èƒ½ä¼šåŒ…å« ROS æ¶ˆæ¯å¤´ï¼Œè¿™é‡Œç›´æ¥å°è¯• imdecode
                # å¦‚æœè§£ç å¤±è´¥ï¼Œå¯èƒ½éœ€è¦è·³è¿‡å‰å‡ ä¸ªå­—èŠ‚çš„ ROS Header
                payload_bytes = sample.payload.to_bytes()           
                # 1. è§£ç å›¾åƒå¹¶è·å–æ—¶é—´æˆ³
                frame, stamp = self.decode_ros2_image(payload_bytes, default_shape=(self.height, self.width, 3))
                if frame is None:
                    print("âš  æ— æ³•è§£ç å›¾åƒ")
                    continue
                
                if self.frame_count % self.skip_n != 0:
                    # å…³é”®ï¼šå³ä½¿ä¸æ¨ç†ï¼Œä¹Ÿè¦å‘å¸ƒ scanï¼Œä¿æŒ RTAB-MAP å¿ƒè·³
                    if self.last_valid_scan is not None:
                        self.publish_as_json(self.last_valid_scan, stamp)
                    continue
                
                # print(f"ğŸ–¼ å›¾åƒè§£ç æˆåŠŸ: shape={frame.shape}, timestamp={stamp:.6f}")
                scan_ranges = np.full(self.num_readings, float('inf'))
                # 2. æ¨ç†æ£€æµ‹
                # if self.frame_count % self.skip_n == 0:
                uv_points, _ = self.detector.get_ground_contact_points(frame, render=False)
                if len(uv_points) > 0:
                    valid_points = 0
                    # print(f"ğŸ” æ¨ç†å®Œæˆï¼Œæ£€æµ‹åˆ° {len(uv_points)} ä¸ªæ¥è§¦ç‚¹")
                    # 4. æŠ•å½±é€»è¾‘ (é€»è¾‘ä¸åŸä»£ç ä¸€è‡´)
                    # for u, v in uv_points:
                    #     res = self.pixel_to_base(u, v)
                        # if res:
                        #         x, y = res
                    xyz_points = self.pixel_to_base_batch(uv_points)
                    # è¿‡æ»¤æ‰æ— æ³•æŠ•å½±åˆ°åœ°é¢çš„ NaN ç‚¹
                    valid_mask = ~np.isnan(xyz_points[:, 0])
                    valid_xyz = xyz_points[valid_mask]
                    if len(valid_xyz) > 0:
                        # valid_xyz = self.check_and_refine_by_angle(valid_xyz)                   
                        for x, y in valid_xyz:
                            # è®¡ç®—ä»åæ ‡åŸç‚¹ $(0, 0)$ åˆ°ç‚¹ $(x, y)$ çš„æ¬§å‡ é‡Œå¾—è·ç¦»
                            # dist = math.hypot(x, y)
                            dist = round(math.hypot(x, y) / 0.02) * 0.02
                            if dist < self.range_min or dist > self.range_max:
                                continue
                            
                            angle = math.atan2(y, x)
                            if not (self.angle_min <= angle <= self.angle_max):
                                print(f"on_image_dataï¼šè§’åº¦åç¦»ï¼Œ{angle}")
                                continue
                                
                            idx = int(round((angle - self.angle_min) / self.angle_increment))
                            idx = max(0, min(idx, self.num_readings - 1))
                            
                            # scan_ranges[idx] = min(scan_ranges[idx], dist)
                            # æ‰©æ•£å¯¼è‡´éšœç¢å¤ªå¤§
                            for di in (-1, 0, 1):
                                j = idx + di
                                if 0 <= j < self.num_readings:
                                    scan_ranges[j] = min(scan_ranges[j], dist)
                                
                                    
                            valid_points += 1

                if self.last_valid_scan is not None:
                    # 1. è¯†åˆ«ä¸¤å¸§éƒ½æœ‰æ•ˆçš„åŒºåŸŸï¼ˆé inf ä¸”åœ¨é‡ç¨‹å†…ï¼‰
                    # æ³¨æ„ï¼šå¦‚æœä½ çš„ scan_ranges åˆå§‹åŒ–ä¸º float('inf')ï¼Œåˆ¤æ–­æœ‰æ•ˆæ€§ç”¨ isfinite
                    current_valid = np.isfinite(scan_ranges)
                    previous_valid = np.isfinite(self.last_valid_scan)
                    
                    # åªæœ‰ä¸¤å¸§éƒ½æœ‰æ•ˆçš„ç‚¹æ‰åšå¹³æ»‘ï¼Œé˜²æ­¢æŠŠâ€œæ–°å‡ºç°çš„éšœç¢ç‰©â€æ‹‰å‡ºæ‹–å½±
                    blend_mask = current_valid & previous_valid
                    
                    # åº”ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ (EMA)
                    # self.scan_alpha å»ºè®®è®¾ä¸º 0.2 ~ 0.3
                    scan_ranges[blend_mask] = (self.scan_alpha * scan_ranges[blend_mask] + 
                                              (1 - self.scan_alpha) * self.last_valid_scan[blend_mask])
                    
                # 5. æ¡ä»¶å‘å¸ƒ
                self.last_valid_scan = scan_ranges.copy()
                self.publish_as_json(scan_ranges, stamp)
                
            except Exception as e:
                print(f"å¤„ç†é”™è¯¯: {e}")
                time.sleep(0.1)

    def get_accurate_stamp(self,payload):
        try:
            # ROS 2 åºåˆ—åŒ–åçš„å‰ 4 å­—èŠ‚æ˜¯å°è£…å¤´ (Representation Identifier)
            # ç´§æ¥ç€å°±æ˜¯æ¶ˆæ¯å†…å®¹ã€‚å¯¹äº Image/CompressedImageï¼Œç¬¬ä¸€ä¸ªå­—æ®µæ˜¯ Headerã€‚
            # Header çš„ç¬¬ä¸€ä¸ªå­—æ®µæ˜¯ Stamp (sec, nanosec)ã€‚
            
            # å°è¯•ä»åç§»é‡ 4 å¼€å§‹è¯»å– (è·³è¿‡ 4 å­—èŠ‚çš„ CDR Header)
            sec, nsec = struct.unpack_from('<II', payload, 4)
            stamp = sec + nsec * 1e-9
            print(f"ğŸ•’ æå–å‡†ç¡®æ—¶é—´æˆ³: {stamp:.6f}")
            return stamp
        except Exception:
            return time.time()
    
    # è¾“å‡ºç»Ÿä¸€ä¸ºbgr
    def decode_ros2_image(self, payload, default_shape=(480, 640, 3)):
        # å…³é”®ä¿®å¤ 1: ç¡®ä¿è¿›å…¥å‡½æ•°çš„æ˜¯ bytes ç±»å‹ï¼Œæˆ–è€…æ˜¯æ”¯æŒåˆ‡ç‰‡çš„è§†å›¾
        if hasattr(payload, 'to_bytes'):
            payload = payload.to_bytes()

        payload_len = len(payload)
        h, w, c = default_shape
        num_pixels = h * w * c
    
        stamp = time.time()
        frame = None
        def save_image(decode_type, max_files=50):
            # --- 3. ä¿å­˜éªŒè¯ ---
            if frame is None:
                return

            debug_dir = 'debug_images'
            if not os.path.exists(debug_dir):
                os.makedirs(debug_dir)

            # 1. æ•°é‡é™åˆ¶æ£€æŸ¥
            files = sorted(glob.glob(os.path.join(debug_dir, "*.jpg")))
            if len(files) >= max_files:
                # åˆ é™¤æœ€æ—©çš„ä¸€å¼  (æŒ‰æ–‡ä»¶åæ’åº)
                try:
                    os.remove(files[0])
                except Exception:
                    pass
            # 3. æ‰§è¡Œä¿å­˜
            filename = f"{debug_dir}/frame_{int(time.time()*1000)}_{decode_type}.jpg"
            cv2.imwrite(filename, frame)
        # print(f"âœ… å·²ä¿å­˜éªŒè¯å›¾ç‰‡: {filename}")
        
        # --- 2. å°è¯• raw Image ---
        # å¦‚æœæ²¡æ‰¾åˆ° JPEG å¤´ï¼Œå¯èƒ½æ˜¯ raw æ ¼å¼
        # æ³¨æ„ï¼šRaw Image ä¹Ÿæœ‰ Headerï¼Œpayload éœ€è¦è·³è¿‡ Header æ‰èƒ½æ­£ç¡® reshape
        # å‡è®¾ Header é•¿åº¦çº¦ä¸º 48 å­—èŠ‚ (è§† frame_id é•¿åº¦è€Œå®š)
        if payload_len >= num_pixels:
            try:
                
                # è¿™æ˜¯ä¸€ä¸ª Trickï¼šä»æœ«å°¾å‘å‰å–æ•°æ®ï¼Œè§„é¿å‰é¢å˜é•¿çš„ Header
                raw_data = np.frombuffer(payload, np.uint8)
                num_pixels = default_shape[0] * default_shape[1] * default_shape[2]
        
                if len(raw_data) >= num_pixels:
                    frame = raw_data[-num_pixels:].reshape(default_shape)
                    # é»˜è®¤ä¸ºRGB
                    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)
                    stamp = self.get_accurate_stamp(payload)
                    # save_image('rgb')
                    return frame, stamp
            except Exception as e:
                print(f"âš  raw Image reshape å¤±è´¥: {e}")
        
        # --- 1. å¤„ç† ROS 2 æ¶ˆæ¯å¤´ (DDS åºåˆ—åŒ–é€šå¸¸ä¼šæœ‰é¢å¤–å¼€é”€) ---
        # ROS2 CompressedImage çš„ä¸€èˆ¬å¸ƒå±€: 
        # [8å­—èŠ‚ Stamp] [Frame_ID é•¿åº¦ + å­—ç¬¦ä¸²] [Format é•¿åº¦ + å­—ç¬¦ä¸² "jpeg"] [æ•°æ®]
        
        # å°è¯•å¯»æ‰¾ JPEG é­”æ³•æ•°å­— (0xFF, 0xD8)
        # é€šå¸¸ JPEG åœ¨ payload ä¸­çš„åç§»é‡åœ¨ 40-100 å­—èŠ‚ä¹‹é—´
        idx = payload.find(b'\xff\xd8')
        if idx != -1:
            # æ‰¾åˆ°äº† JPEG å¼€å¤´ï¼Œè¯´æ˜æ˜¯å‹ç¼©å›¾åƒ
            try:
                stamp = self.get_accurate_stamp(payload)
                # è§£ç  JPEG
                jpeg_data = payload[idx:]
                nparr = np.frombuffer(jpeg_data, np.uint8)
                frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
                # save_image('compressed')
                if frame is not None:
                    return frame, stamp
            except Exception as e:
                print(f"âš  jpeg Image reshape å¤±è´¥: {e}")
        return None, stamp
    
    def publish_as_json(self, ranges,stamp):
        """å°†é›·è¾¾æ•°æ®ä»¥ JSON æ ¼å¼å‘å¸ƒåˆ° Zenoh"""
        # æ›¿æ¢ inf ä¸ºä¸€ä¸ªå¤§æ•°ï¼Œå› ä¸ºæ ‡å‡† JSON ä¸æ”¯æŒ Infinity
            
        safe_value = self.range_max + 1
        # ranges_list = [float(r) if (np.isfinite(r) and r < self.range_max) else safe_value for r in ranges]
        ranges_list = [float(r) if np.isfinite(r) else safe_value for r in ranges]
        msg = {
            "stamp": stamp,
            "frame_id": "base_link",
            "angle_min": self.angle_min,
            "angle_max": self.angle_max,
            "angle_increment": self.angle_increment,
            "ranges": ranges_list,
            "range_min": self.range_min,
            "range_max": self.range_max
        }

        # if np.any(np.isfinite(ranges)):
        print(f"ğŸ“¡ å‘å¸ƒæœ‰æ•ˆjson {ranges_list}")
        payload = json.dumps(msg).encode("utf-8")
        self.pub.put(payload=payload,
                        encoding="application/json")


    def pixel_to_base(self, u, v):
        """
        æ•°å­¦åŸç†ï¼šå°„çº¿-å¹³é¢ç›¸äº¤æ¨¡å‹ (Ray-Plane Intersection)
        ç›®çš„ï¼šå°†å›¾åƒåæ ‡ (u, v) æ˜ å°„åˆ°åœ°é¢å‚è€ƒç³» (X, Y, Z=0)
        """

        # --- 1. æ¶ˆé™¤ç•¸å˜ä¸å½’ä¸€åŒ– (Undistortion & Normalization) ---
        # æ•°å­¦åŸç†ï¼šé’ˆå­”ç›¸æœºé€†æ¨¡å‹
        # é€šè¿‡ç›¸æœºå†…å‚çŸ©é˜µ K çš„é€†è¿ç®—å’Œç•¸å˜ç³»æ•°ï¼Œå°†åƒç´ åæ ‡è½¬æ¢ä¸ºå½’ä¸€åŒ–åƒå¹³é¢åæ ‡ (xn, yn)ã€‚
        # xn = (u - cx) / fx, yn = (v - cy) / fy (åœ¨æ— ç•¸å˜ç†æƒ³çŠ¶æ€ä¸‹)
        # æ­¤æ—¶ xn, yn è¡¨ç¤ºåœ¨ç„¦è· f=1 å¤„çš„ç‰©ç†å°ºå¯¸ã€‚
        pts = np.array([[[u, v]]], dtype=np.float32)
        undist_pts = cv2.undistortPoints(pts, self.K, self.dist_coeffs)
        xn, yn = undist_pts[0][0]

        # --- 2. åæ ‡ç³»é‡æ˜ å°„ï¼šå…‰å­¦ç³»åˆ°æœ¬ä½“ç³» (Optical Frame -> Base Frame) ---
        # æ•°å­¦åŸç†ï¼šæ¬§å¼ç©ºé—´è½´å‘å¯¹é½ (REP-103 æ ‡å‡†)
        # ç›¸æœºå…‰å­¦ç³» (Optical): Zå‘å‰, Xå‘å³, Yå‘ä¸‹
        # æœºå™¨äººæœ¬ä½“ç³» (Base): Xå‘å‰, Yå‘å·¦, Zå‘ä¸Š
        # æ˜ å°„å…³ç³»ï¼šBase_X = Opt_Z(1.0), Base_Y = -Opt_X(-xn), Base_Z = -Opt_Y(-yn)
        # v_base_raw æ˜¯ä»ç›¸æœºå…‰å¿ƒå‘å‡ºçš„ã€åœ¨æœºå™¨äººæ°´å¹³è§†è§’ä¸‹çš„æ–¹å‘å‘é‡ã€‚
        v_base_raw = np.array([1.0, -xn, -yn]) 

        # --- 3. ä¿¯ä»°è§’æ—‹è½¬å¤„ç† (Pitch Rotation) ---
        # æ•°å­¦åŸç†ï¼šç»• Y è½´çš„æ—‹è½¬å˜æ¢ (Rotation Matrix)
        # ç›¸æœºå‘ä¸‹ä½å¤´ (pitch > 0)ï¼Œç›¸å¯¹äºæœºå™¨äººç³»æ˜¯ä¸€ä¸ªç»• Y è½´çš„æ—‹è½¬ã€‚
        # æ—‹è½¬çŸ©é˜µ R_y(p) ä½œç”¨äºå‘é‡ï¼š
        # [rb_x]   [ cos(p)  0  sin(p)] [v_raw_x]
        # [rb_y] = [   0     1     0   ] [v_raw_y]
        # [rb_z]   [-sin(p)  0  cos(p)] [v_raw_z]
        # è¯¥æ­¥éª¤å°†â€œæ°´å¹³ç›¸æœºç³»â€ä¸‹çš„å°„çº¿æ—‹è½¬è‡³â€œå®é™…å®‰è£…å€¾è§’â€ä¸‹çš„å°„çº¿æ–¹å‘å‘é‡ã€‚
        
        p = self.camera_pitch
        c, s = np.cos(p), np.sin(p)
        
        rb_x = v_base_raw[0] * c + v_base_raw[2] * s
        rb_y = v_base_raw[1]
        rb_z = -v_base_raw[0] * s + v_base_raw[2] * c

        # --- 4. å°„çº¿ä¸åœ°é¢æ±‚äº¤ (Ray-Plane Intersection) ---
        # æ•°å­¦åŸç†ï¼šçº¿æ€§æ¯”ä¾‹ç›¸ä¼¼æ€§ / å‚æ•°åŒ–ç›´çº¿æ–¹ç¨‹
        # å‡è®¾åœ°é¢æ–¹ç¨‹ä¸º Z = 0ã€‚ç›¸æœºå…‰å¿ƒåœ¨ Base ç³»ä¸‹çš„åæ ‡ä¸º (camera_x_offset, 0, camera_height)ã€‚
        # å°„çº¿æ–¹ç¨‹ï¼šP = P_camera + t * V_ray
        # åˆ†è§£åˆ° Z è½´ï¼š0 = camera_height + t * rb_z  =>  t = -camera_height / rb_z
        # å…¶ä¸­ t æ˜¯ç¼©æ”¾å› å­ï¼Œè¡¨ç¤ºå°„çº¿ä»å…‰å¿ƒåˆ°è¾¾åœ°é¢æ‰€éœ€çš„æ­¥é•¿ã€‚
        
        
        # ç‰©ç†çº¦æŸï¼šå¦‚æœ rb_z >= 0ï¼Œè¯´æ˜å°„çº¿æ°´å¹³æˆ–å‘ä¸Šå°„å‘å¤©ç©ºï¼Œæ°¸è¿œä¸ä¼šä¸åœ°é¢ç›¸äº¤ã€‚
        if rb_z >= -1e-6: 
            # print(f"å°„çº¿å°„å‘å¤©ç©ºï¼Œæ— æ³•ä¸åœ°é¢ç›¸äº¤")
            return None 
        
        t = -self.camera_height / rb_z
        
        # --- 5. å¹³ç§»è¡¥å¿ (Translation Compensation) ---
        # æ•°å­¦åŸç†ï¼šåˆšä½“å˜æ¢çš„å¹³ç§»éƒ¨åˆ†
        # X = å°„çº¿åœ¨ X è½´çš„å»¶ä¼¸ + ç›¸æœºç›¸å¯¹äºæœºå™¨äººä¸­å¿ƒçš„å®‰è£…åç§»
        # Y = å°„çº¿åœ¨ Y è½´çš„å»¶ä¼¸ (é€šå¸¸ç›¸æœºå±…ä¸­å®‰è£…ï¼Œåç§»ä¸º 0)
        X = t * rb_x + self.camera_x_offset
        Y = t * rb_y
        
        return X, Y
    
    def pixel_to_base_batch(self, uv_points):
        """
        æ‰¹é‡å°†åƒç´ åæ ‡ (u, v) æ˜ å°„åˆ°åœ°é¢å‚è€ƒç³» (X, Y, Z=0)
        Args:
            uv_points: np.ndarray, shape [N, 2], å…ƒç´ ä¸º [[u1, v1], [u2, v2], ...]
        Returns:
            points_base: np.ndarray, shape [N, 2], å…ƒç´ ä¸º [[X1, Y1], [X2, Y2], ...]
                        æ— æ³•ç›¸äº¤çš„ç‚¹å°†è¢«è¿‡æ»¤æˆ–è¿”å› NaN
        """
        if len(uv_points) == 0:
            return np.empty((0, 2))

        # --- ä¼˜åŒ–1ï¼šROIè¿‡æ»¤ (åªçœ‹å›¾åƒé«˜åº¦ 85% ä»¥ä¸Šçš„éƒ¨åˆ†ï¼Œé˜²æ­¢è½¦å¤´å¹²æ‰°) ---
        uv_points = np.atleast_2d(uv_points)
        mask_roi = uv_points[:, 1] < (self.height * 0.85)
        # --- 1. æ‰¹é‡æ¶ˆé™¤ç•¸å˜ä¸å½’ä¸€åŒ– ---
        # uv_points shape: [N, 2] -> reshape ä¸º cv2 è¦æ±‚çš„ [N, 1, 2]
        pts = np.array(uv_points, dtype=np.float32).reshape(-1, 1, 2)
        undist_pts = cv2.undistortPoints(pts, self.K, self.dist_coeffs)
        # å¾—åˆ°å½’ä¸€åŒ–åæ ‡ xn, yn (shape: [N, 2])
        n_coords = undist_pts.reshape(-1, 2)
        xn = n_coords[:, 0]
        yn = n_coords[:, 1]

        # --- 2. åæ ‡ç³»é‡æ˜ å°„ (Optical -> Base) ---
        # v_base_raw shape: [N, 3]
        ones = np.ones_like(xn)
        v_base_raw = np.column_stack([ones, -xn, -yn])

        # --- 3. æ‰¹é‡ä¿¯ä»°è§’æ—‹è½¬å¤„ç† ---
        p = self.camera_pitch
        c, s = np.cos(p), np.sin(p)
        
        # æŒ‰ç…§ä½ æä¾›çš„å…¬å¼è¿›è¡ŒçŸ©é˜µè¿ç®—
        rb_x = v_base_raw[:, 0] * c + v_base_raw[:, 2] * s
        rb_y = v_base_raw[:, 1]
        rb_z = -v_base_raw[:, 0] * s + v_base_raw[:, 2] * c

        # --- 4. å°„çº¿ä¸åœ°é¢æ±‚äº¤ ---
        # ç‰©ç†çº¦æŸè¿‡æ»¤ï¼šåªä¿ç•™å°„å‘åœ°é¢çš„ç‚¹ (rb_z < -1e-6)
        # valid_mask = rb_z < -1e-6
        valid_mask = (rb_z < -0.01) & mask_roi
        
        # åˆå§‹åŒ–ç»“æœçŸ©é˜µ
        num_pts = len(uv_points)
        results = np.full((num_pts, 2), np.nan) # é»˜è®¤å¡«å…… NaN è¡¨ç¤ºæ— æ•ˆç‚¹

        if not np.any(valid_mask):
            return results

        # åªè®¡ç®—æœ‰æ•ˆç‚¹
        t = -self.camera_height / rb_z[valid_mask]
        
        # --- 5. å¹³ç§»è¡¥å¿ ---
        X = t * rb_x[valid_mask] + self.camera_x_offset
        Y = t * rb_y[valid_mask]
        
        # --- ä¼˜åŒ–3ï¼šç‰©ç†è·ç¦»äºŒæ¬¡è¿‡æ»¤ (è¿‡æ»¤æ‰ 0.2m ä»¥å†…çš„æŠ–åŠ¨ç‚¹) ---
        dist_sq = X**2 + Y**2
        phys_mask = dist_sq > (0.2 ** 2)
        
        # å®šä¹‰æœ€ç»ˆèƒ½å¤Ÿå†™å…¥ results çš„å¸ƒå°”æ©ç ï¼ˆé•¿åº¦ä¸º num_ptsï¼‰
        valid_and_far = np.zeros(num_pts, dtype=bool)
        valid_and_far[valid_mask] = phys_mask 

        # ã€å…³é”®ä¿®æ­£ã€‘ï¼šä½¿ç”¨ phys_mask æå– X å’Œ Y ä¸­çœŸæ­£æœ‰æ•ˆçš„å…ƒç´ 
        results[valid_and_far] = np.column_stack([X[phys_mask], Y[phys_mask]])

        return results
    
    def refine_wall_points(self, points_xyz):
        """
        åˆ©ç”¨ç›´çº¿æ‹Ÿåˆä¿®æ­£æ²¿ç€å¢™æ–¹å‘çš„é€è§†åç§»
        """
        # å¦‚æœç‚¹å¤ªå°‘ï¼Œæ— æ³•æ‹Ÿåˆç›´çº¿ï¼Œç›´æ¥è¿”å›åŸæ•°æ®
        if len(points_xyz) < 10: 
            return points_xyz
        
        try:
            # 1. ä½¿ç”¨ cv2.fitLine è¿›è¡Œç›´çº¿æ‹Ÿåˆ (æœ€å°äºŒä¹˜æ³•)
            # è¿”å› [vx, vy, x0, y0]ï¼Œå…¶ä¸­ (vx, vy) æ˜¯æ–¹å‘å‘é‡ï¼Œ(x0, y0) æ˜¯ç›´çº¿ä¸Šçš„ä¸€ç‚¹
            # è¿™é‡Œçš„ points_xyz éœ€è¦æ˜¯ float32 ç±»å‹
            data = points_xyz[:, :2].astype(np.float32)
            [vx, vy, x0, y0] = cv2.fitLine(data, cv2.DIST_L2, 0, 0.01, 0.01)
            
            # 2. å‡ ä½•æŠ•å½±ï¼šå°†åŸå§‹æ•£ç‚¹æŠ•å½±åˆ°æ‹Ÿåˆå‡ºçš„ç›´çº¿ä¸Š
            # å…¬å¼ï¼šP_new = P_anchor + <P_orig - P_anchor, V_dir> * V_dir
            refined_points = []
            vx, vy, x0, y0 = float(vx), float(vy), float(x0), float(y0)
            
            for x, y in data:
                # è®¡ç®—å‘é‡ (x-x0, y-y0) åœ¨æ–¹å‘å‘é‡ (vx, vy) ä¸Šçš„æŠ•å½±é•¿åº¦
                dot_product = (x - x0) * vx + (y - y0) * vy
                # å¾—åˆ°ç›´çº¿ä¸Šçš„æ–°ç‚¹
                new_x = x0 + dot_product * vx
                new_y = y0 + dot_product * vy
                refined_points.append([new_x, new_y])
                
            return np.array(refined_points)
        except Exception as e:
            print(f"ç›´çº¿æ‹Ÿåˆå¤±è´¥: {e}")
            return points_xyz
        
    def check_and_refine_by_angle(self, points_xyz):
        """
        åŸºäºè§‚æµ‹å‡ ä½•è§’åº¦å†³å®šæ˜¯å¦æ‰§è¡Œæ‹Ÿåˆ
        """
        if len(points_xyz) < 15:
            return points_xyz

        try:
            # 1. ç²—ç•¥æ‹Ÿåˆï¼Œè·å–å¢™çš„æ–¹å‘å‘é‡ (vx, vy)
            data = points_xyz[:, :2].astype(np.float32)
            [vx, vy, x0, y0] = cv2.fitLine(data, cv2.DIST_L2, 0, 0.01, 0.01)
            wall_vec = np.array([vx[0], vy[0]])

            # 2. è®¡ç®—è§‚æµ‹å‘é‡ (ä»åŸç‚¹åˆ°ç‚¹äº‘ä¸­å¿ƒ)
            center_x = np.mean(data[:, 0])
            center_y = np.mean(data[:, 1])
            view_vec = np.array([center_x, center_y])
            
            # å½’ä¸€åŒ–å‘é‡
            wall_vec /= np.linalg.norm(wall_vec)
            view_vec /= np.linalg.norm(view_vec)

            # 3. è®¡ç®—å¤¹è§’ä½™å¼¦å€¼ (å–ç»å¯¹å€¼ï¼Œå› ä¸ºæ–¹å‘å‘é‡æ˜¯åŒå‘çš„)
            cos_theta = abs(np.dot(wall_vec, view_vec))
            
            # 4. åˆ¤å®šé€»è¾‘
            # cos_theta > 0.866 æ„å‘³ç€å¤¹è§’å°äº 30 åº¦ (å±äºæ å°„è§’/å°å¤¹è§’)
            if cos_theta > 0.85:
                # print(f"ğŸ“ æ£€æµ‹åˆ°å°å¤¹è§’ ({cos_theta:.2f})ï¼Œå¯åŠ¨å¼ºåŠ› RANSAC çº å")
                return self.refine_wall_points(points_xyz) 
            else:
                # print(f"å¹³è§†è§†è§’ï¼Œæ•°æ®ç½®ä¿¡åº¦é«˜ï¼Œä»…åšè½»å¾®å¹³æ»‘")
                return points_xyz

        except Exception as e:
            return points_xyz
        
    def generate_and_publish_pointcloud(self, pseudo_pixels, stamp):
        """
        å°†åƒç´ ç‚¹è½¬æ¢ä¸º 3D ç‚¹äº‘å¹¶å‘å¸ƒ
        """
        if not pseudo_pixels:
            return

        pc_points = []
        for u, v in pseudo_pixels:
            # å¤ç”¨ä½ ç°æœ‰çš„æŠ•å½±é€»è¾‘ (åƒç´  -> æœºå™¨äººåŸºåº§åæ ‡ç³»)
            # å‡è®¾ä½ çš„ pixel_to_base è¿”å› (x, y)ï¼Œå¯¹äºåœ°é¢ç‚¹äº‘ï¼Œz é€šå¸¸è®¾ä¸º 0 æˆ–éšœç¢ç‰©é«˜åº¦
            res = self.pixel_to_base(u, v)
            if res:
                x, y = res
                # è¿™é‡Œå¯ä»¥æ·»åŠ ç®€å•çš„è¿‡æ»¤é€»è¾‘ï¼Œæ¯”å¦‚è·ç¦»å¤ªè¿œçš„ç‚¹ä¸æ”¾å…¥ç‚¹äº‘
                dist = math.hypot(x, y)
                if self.range_min <= dist <= self.range_max:
                    # æ„é€ ç‚¹äº‘æ•°æ® [x, y, z]
                    # æ³¨æ„ï¼šå¦‚æœæ˜¯åœ°é¢è¾¹ç¼˜ï¼Œz é€šå¸¸æ¥è¿‘ 0
                    pc_points.append([float(x), float(y), 0.0])

        if pc_points:
            # å°†ç‚¹äº‘å‘å¸ƒå‡ºå»
            # å¦‚æœä½ ä½¿ç”¨ Zenohï¼Œå¯ä»¥å°†å…¶åºåˆ—åŒ–ä¸º JSON æˆ–äºŒè¿›åˆ¶æ•°ç»„
            pc_data = {
                "timestamp": stamp,
                "frame_id": "base_link",
                "points": pc_points  # æ ¼å¼ä¸º [[x1,y1,z1], [x2,y2,z2], ...]
            }
            payload = json.dumps(pc_data).encode("utf-8")
            self.pointcloud_pub.put(payload=payload,
                            encoding="application/json")

if __name__ == '__main__':
    # 1. é…ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="Zenoh YOLO Segmentation to LaserScan Node")
    parser.add_argument(
        '--config', 
        type=str, 
        default='robot/config/imx219.json', 
        help='Path to the camera configuration JSON file (default: config.json)'
    )
    
    args = parser.parse_args()

    # 2. ä¼ å…¥è§£æåçš„è·¯å¾„
    try:
        node = ZenohSegScan(config_path=args.config)
        
        print(f"ğŸŒŸ èŠ‚ç‚¹å·²å¯åŠ¨ï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶: {args.config}")
        while True:
            time.sleep(1)
            
    except FileNotFoundError:
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°é…ç½®æ–‡ä»¶ '{args.config}'ï¼Œè¯·æ£€æŸ¥è·¯å¾„ã€‚")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æ­£åœ¨å…³é—­ Zenoh èŠ‚ç‚¹...")
    finally:
        # å»ºè®®åœ¨ç±»ä¸­æ·»åŠ ä¸€ä¸ª close æ–¹æ³•æˆ–ç›´æ¥åœ¨è¿™é‡Œå…³é—­ session
        if 'node' in locals():
            node.session.close()